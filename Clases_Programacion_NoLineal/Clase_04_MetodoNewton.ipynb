{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        },
        "id": "y2esBYYlYwN0"
      },
      "source": [
        "### Introducción a la Investigación Operativa y la Optimización\n",
        "\n",
        "### • Clase 4  - Método de Newton\n",
        "\n",
        "**Nazareno Faillace Mullen - Departamento de Matemática, FCEN, UBA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "fuyhdVL6YwN1"
      },
      "source": [
        "### Comentario sobre Sección Áurea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "n5N5KKCDYwN1"
      },
      "source": [
        "Definimos $\\varphi\\colon [0,+\\infty)\\rightarrow \\mathbb{R}$ de la siguiente manera:\n",
        "$$\\varphi(t)=f(x+td)$$\n",
        "__Definición (Función unimodal):__ una función continua $\\varphi\\colon [0,+\\infty)\\rightarrow \\mathbb{R}$ se dice unimodal si admite un conjunto de minimizadores $[t_1, t_2]$ y es estrictamente decreciente en $[0,t_1]$ ($t_1\\neq 0$) y estrictamente creciente en $[t_2, +\\infty)$\n",
        "\n",
        "<img src=\"https://i.postimg.cc/KzYJR30n/unimodal.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_qODmiDYwN1"
      },
      "source": [
        "Cuando $\\varphi$ es unimodal, la sección áurea funciona muy bien para encontrar una aproximación al minimizador. Si $\\varphi$ no es unimodal, este algoritmo puede no ser eficiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsOaOnmuYwN1"
      },
      "source": [
        "Problema: función de Rosenbrock comenzando en $(0,0)$\n",
        "\n",
        "<img src=\"https://i.postimg.cc/tJSk3qmL/no-unimodal.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "_b1uL9-cYwN1"
      },
      "source": [
        "## Método de Newton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "SLQwdeUCYwN2"
      },
      "source": [
        "En este método, se elige como dirección de descenso:\n",
        "$$d = -Hf(x)^{-1}\\nabla f(x)$$\n",
        "Notar que, si $Hf(x)$ es definida positiva, $d$ es dirección descenso:\n",
        "$$\\nabla f(x)^T d= -\\nabla f(x)^THf(x)^{-1}\\nabla f(x) < 0$$\n",
        "\n",
        "__Observación:__ $d$ puede no estar bien definido si $Hf(x)$ es singular o puede no ser una dirección de descenso si $Hf(x)$ no es definida positiva.\n",
        "\n",
        "__Teorema:__ si $Hf(x)$ es definida positiva para todo $x\\in\\mathbb{R}^n$, el Método de Newton es globalmente convergente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "bj-3GhEEYwN2"
      },
      "source": [
        "__Algoritmo del Método de Newton para $f$ tal que $Hf(x)$ es definida positiva para todo $x\\in\\mathbb{R}^n$__\n",
        "\n",
        "Dados: $f, x_0 \\in \\mathbb{R}^n,\\; \\varepsilon>0,\\; k_{MAX}>0$ <br>\n",
        "$k=0$ <br>\n",
        "REPETIR mientras $\\lVert\\nabla f(x_{k})\\rVert > \\varepsilon$ y $k<k_{MAX}$: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Definir $d_{k}$ como la solución de $Hf(x_{k})d_{k} = -\\nabla f(x_{k})$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Determinar el tamaño del paso $t_k > 0$ (con sección áurea, Armijo o Wolfe) <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Hacer $x_{k+1} = x_{k} + t_kd_{k}$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; k = k + 1 <br>\n",
        "DEVOLVER $x_k$\n",
        "\n",
        "**Obs.:** para definir $d_k$ utilizar el comando `np.linalg.solve` de la siguiente manera: `dk = np.linalg.solve(H,g)` donde `H `es  $Hf(x_k)$ y `g` es $-\\nabla f(x_{k})$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAZTNb3XYwN2"
      },
      "source": [
        "### Método de Newton para funciones cuadráticas\n",
        "\n",
        "En el caso de las funciones cuadráticas $f(x)=\\frac{1}{2}x^T A x + bx + c$ con $A$ simétrica definida positiva, se tiene que:\n",
        "$$Hf(x) = A$$\n",
        "\n",
        "Dados: $A, b, x_0 \\in \\mathbb{R}^n,\\; \\varepsilon>0,\\; k_{MAX}>0$ <br>\n",
        "$k=0$ <br>\n",
        "REPETIR mientras $\\lVert Ax + b\\rVert > \\varepsilon$ y $k<k_{MAX}$: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Definir $d_{k}$ como la solución de $Ad_{k} = -(Ax_k + b)$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Hacer $x_{k+1} = x_{k} + d_{k}$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; k = k + 1 <br>\n",
        "DEVOLVER $x_k$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SluGZPFtYwN2"
      },
      "source": [
        "# Ejercicios\n",
        "\n",
        "1. Implementar el Método de Newton para funciones cuadráticas.\n",
        "2. Comparar su desempeño (en términos de cantidad de iteraciones) con el de Método de Gradiente y el de Gradiente Conjugado, para las funciones cuadráticas dadas por $f(x)=\\frac{1}{2}x^T A_i x$ para cada una de las $A_i$ que figuran debajo. Probar con puntos iniciales que se encuentren _lejos_ del minimizador $(0,0)$\n",
        "3. ¿Qué ocurre si hacemos $x_{k+1} = x_k + \\gamma d_k$ con $\\gamma\\in (0, 1]$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGhcXxm7YwN2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "\n",
        "A1 = np.array([[8, 3, 3, 6, 5, 4, 4, 3, 6, 3],\n",
        "             [3, 4, 2, 2, 2, 1, 3, 3, 3, 2],\n",
        "             [3, 2, 5, 2, 1, 2, 4, 2, 4, 1],\n",
        "             [6, 2, 2, 6, 3, 2, 4, 2, 4, 2],\n",
        "             [5, 2, 1, 3, 5, 4, 1, 2, 4, 3],\n",
        "             [4, 1, 2, 2, 4, 5, 1, 2, 5, 2],\n",
        "             [4, 3, 4, 4, 1, 1, 6, 2, 4, 2],\n",
        "             [3, 3, 2, 2, 2, 2, 2, 4, 4, 2],\n",
        "             [6, 3, 4, 4, 4, 5, 4, 4, 8, 3],\n",
        "             [3, 2, 1, 2, 3, 2, 2, 2, 3, 4]])\n",
        "\n",
        "A2 = np.array([[2, 0, 1, 0, 1],\n",
        "               [0, 2, 1, 1, 1],\n",
        "               [1, 1, 3, 1, 1],\n",
        "               [0, 1, 1, 1, 0],\n",
        "               [1, 1, 1, 0, 2]])\n",
        "\n",
        "A3 = np.diag(np.random.randint(1, 5, 100))\n",
        "\n",
        "A4 = np.array([[10, 0], [0, 1]])\n",
        "\n",
        "A5 = np.array([[1, -1], [0, 0.8]])\n",
        "\n",
        "A6 = np.array([[163., 162., 171.,  -9.,   0.,   0.],\n",
        "               [162., 163., 171.,  -9.,   0.,   0.],\n",
        "               [171., 171., 181.,  -9.,   0.,   0.],\n",
        "               [ -9.,  -9.,  -9.,   1.,   0.,   0.],\n",
        "               [  0.,   0.,   0.,   0.,   1.,   0.],\n",
        "               [  0.,   0.,   0.,   0.,   0.,   1.]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Ejercicio 1:\n",
        "\n",
        "def met_newton_fciones_cuadraticas(A, b, x0, eps=1e-8, k_max=1000):\n",
        "  k=0\n",
        "  x_k = np.array(x0)\n",
        "  while np.linalg.norm(A @ x_k + b) > eps  and  k < k_max:\n",
        "    d_k = np.linalg.solve(A, -A @ x_k - b)\n",
        "    x_k = x_k + d_k\n",
        "    k = k + 1\n",
        "  return x_k, k\n"
      ],
      "metadata": {
        "id": "o_4rN6RvRZTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Ejercicio 2:\n",
        "#Probar con puntos iniciales que se encuentren lejos del minimizador (0,0)\n",
        "n_A1 = A1[0].shape\n",
        "x_0_A1 = np.ones(n_A1)\n",
        "b_A1 = np.zeros(n_A1)\n",
        "min_newton_cuad_A1, iter_newton_cuad_A1 = met_newton_fciones_cuadraticas(A1, b_A1, x_0_A1)\n",
        "print(f\"Con Newton, A1 realiza {iter_newton_cuad_A1} iteracion/es.\")\n",
        "\n",
        "n_A2 = A2[0].shape\n",
        "x_0_A2 = np.array([10, 10, 10, 10, 10]) #x_0_A2 = np.ones(n_A2)\n",
        "b_A2 = np.zeros(n_A2)\n",
        "min_newton_cuad_A2, iter_newton_cuad_A2 = met_newton_fciones_cuadraticas(A2, b_A2, x_0_A2)\n",
        "print(f\"Con Newton, A2 realiza {iter_newton_cuad_A2} iteracion/es.\")\n",
        "\n",
        "n_A3 = A3[0].shape\n",
        "x_0_A3 = np.ones(n_A3)\n",
        "b_A3 = np.zeros(n_A3)\n",
        "min_newton_cuad_A3, iter_newton_cuad_A3 = met_newton_fciones_cuadraticas(A3, b_A3, x_0_A3)\n",
        "print(f\"Con Newton, A3 realiza {iter_newton_cuad_A3} iteracion/es.\")\n",
        "\n",
        "n_A4 = A4[0].shape\n",
        "x_0_A4 = np.array([5, 5])\n",
        "b_A4 = np.zeros(n_A4)\n",
        "min_newton_cuad_A4, iter_newton_cuad_A4 = met_newton_fciones_cuadraticas(A4, b_A4, x_0_A4)\n",
        "print(f\"Con Newton, A4 realiza {iter_newton_cuad_A4} iteracion/es.\")\n",
        "\n",
        "n_A5 = A5[0].shape\n",
        "x_0_A5 = np.array([100, 100])\n",
        "b_A5 = np.zeros(n_A5)\n",
        "min_newton_cuad_A5, iter_newton_cuad_A5 = met_newton_fciones_cuadraticas(A5, b_A5, x_0_A5)\n",
        "print(f\"Con Newton, A5 realiza {iter_newton_cuad_A5} iteracion/es.\")\n",
        "\n",
        "n_A6 = A6[0].shape\n",
        "x_0_A6 = np.array([1000, 1000, 1000, 1000, 1000, 1000])\n",
        "b_A6 = np.zeros(n_A6)\n",
        "min_newton_cuad_A6, iter_newton_cuad_A6 = met_newton_fciones_cuadraticas(A6, b_A6, x_0_A6)\n",
        "print(f\"Con Newton, A6 realiza {iter_newton_cuad_A6} iteracion/es.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR81xkb0RV_n",
        "outputId": "3a57851a-c5e6-4a8b-f437-09e17a6ca51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Con Newton, A1 realiza 1 iteracion/es.\n",
            "Con Newton, A2 realiza 1 iteracion/es.\n",
            "Con Newton, A3 realiza 1 iteracion/es.\n",
            "Con Newton, A4 realiza 1 iteracion/es.\n",
            "Con Newton, A5 realiza 1 iteracion/es.\n",
            "Con Newton, A6 realiza 1 iteracion/es.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Ejercicio 3:\n",
        "# ¿Qué pasa si hacemos x_k = x_k + γ*d_k con γ∈(0,1] ?\n",
        "\n",
        "#Si hacemos x_k = x_k + np.random.rand()*d_k, el método de Newton realiza más de 1 iteracion."
      ],
      "metadata": {
        "id": "bqvAmJPQX9Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "-6poyFXxYwN2"
      },
      "source": [
        "## ¿Qué pasa si $Hf(x)$ no es definida positiva o si es singular?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njpN3bpbYwN2"
      },
      "source": [
        "**Recordar:** $A\\in\\mathbb{R}^{n\\times n}$ inversible $\\Leftrightarrow$ $0$ no es autovalor de $A$.<br><br>\n",
        "**Recordar:** $A\\in\\mathbb{R}^{n\\times n}$ simétrica, $A$ es definida positiva $\\Leftrightarrow$ todos los autovalores de $A$ son positivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "7E1OCImEYwN2"
      },
      "source": [
        "### Modificación de Levenberg-Marquardt\n",
        "\n",
        "Considerar\n",
        "$$x_{k+1} = x_{k} - t_k(Hf(x_{k})+\\mu I)^{-1}\\nabla f(x_{k})$$\n",
        "\n",
        "donde $\\mu>0$ es lo suficientemente grande como para que $B_{k}= Hf(x_{k})+\\mu I$ sea definida positiva.\n",
        "\n",
        "__Obs:__ si $\\mu$ es demasiado grande, $d_{k}$ tiende a estar en la dirección de $-\\nabla f(x_{k})$, pues $(Hf(x_{k})+\\mu I)^{-1}\\nabla f(x_{k}) \\approx \\frac{1}{\\mu}\\nabla f(x_{k})$ . En cambio, si $\\mu$ es pequeño, $d_{k}$ se parece más a la dirección de descenso del Método de Newton\n",
        "\n",
        "Con la modificación de L-M, se obtiene un método que utiliza las ventajas del Método del Gradiente y del Método de Newton. Pensándolo con ideas generales:\n",
        "* cerca del mínimo $\\approx$ $Hf(x)$ definida positiva $\\approx$ $\\mu=0$ o $\\mu$ pequeño $\\approx$ Método de Newton $\\approx$ convergencia rápida cerca de un mínimo\n",
        "* lejos del mínimo $\\approx$ $Hf(x)$ no definida positiva $\\approx$ $\\mu$ grande $\\approx$ Método del gradiente $\\approx$ más velocidad de descenso\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "QwjYI-obYwN3"
      },
      "source": [
        "__Obs:__ Como pedíamos que $f\\in C^3$, en particular resulta que $Hf(x)$ es simétrica $\\forall x \\in \\mathbb{R}^n$, entonces los autovalores de $Hf(x)$ son reales $\\forall x \\in \\mathbb{R}^n$.\n",
        "\n",
        "__Obs:__ Si $\\lambda_1, \\dots, \\lambda_n$ son los autovalores de $Hf(x)$, entonces $\\lambda_1+\\mu, \\dots, \\lambda_n+\\mu$ son los autovalores de $B=Hf(x)+\\mu I$, y $B$ tiene los mismos autovectores que $Hf(x)$. Sea $v_i$ autovector de $Hf(x)$:\n",
        "$$\\begin{array}{rcl} Bv_i &=& (Hf(x)+\\mu I)v_i \\\\ &=& Hf(x)v_i+\\mu Iv_i \\\\ &=& \\lambda_iv_i+\\mu v_i \\\\ &=& (\\lambda_i+\\mu)v_i \\end{array}$$\n",
        "Entonces, en caso de que $Hf(x)$ no sea definida positiva, se puede utilizar su mínimo autovalor como una aproximación a $-\\mu$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "GI8TqiPdYwN3"
      },
      "source": [
        "__Algoritmo del Método de Newton con modificación de Levenberg-Marquardt__\n",
        "\n",
        "Dados: $f, x_0 \\in \\mathbb{R}^n,\\; k_{MAX}>0,\\; \\varepsilon>0,\\; \\gamma>0$ <br>\n",
        "$k=0$ <br>\n",
        "REPETIR mientras $\\lVert\\nabla f(x_{k})\\rVert > \\varepsilon$ y $k<k_{MAX}$: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $B = Hf(x_{k})$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $\\mu = \\min \\{ \\lambda \\colon \\lambda \\text{ es autovalor de } B\\}$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Si $\\mu \\leq 0$: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $B = B+(-\\mu+\\gamma)I$  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Definir $d_{k}$ como la solución de $Bd_{k} = -\\nabla f(x_{k})$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Determinar el tamaño del paso $t_k > 0$ (con sección áurea, Armijo o Wolfe)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Hacer $x_{k+1} = x_{k} + t_kd_{k}$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; k = k + 1 <br>\n",
        "DEVOLVER $x_k$\n",
        "\n",
        "Utilizar la función `np.linalg.eigvals(B)` para calcular los autovalores de $B$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jz1zpUWYwN3"
      },
      "source": [
        "## Aproximando el Hessiano de $f$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpvE6g3TYwN3"
      },
      "source": [
        "Aproximaremos el valor del Hessiano en cierto $x$, teniendo en cuenta que:\n",
        "$$Hf(x)={\\begin{pmatrix}{\\frac  {\\partial ^{2}f}{\\partial x_{1}^{2}}}&{\\frac  {\\partial ^{2}f}{\\partial x_{1}\\partial x_{2}}}&\\cdots &{\\frac  {\\partial ^{2}f}{\\partial x_{1}\\partial x_{n}}}\\\\{\\frac  {\\partial ^{2}f}{\\partial x_{2}\\partial x_{1}}}&{\\frac  {\\partial ^{2}f}{\\partial x_{2}^{2}}}&\\cdots &{\\frac  {\\partial ^{2}f}{\\partial x_{2}\\partial x_{n}}}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\{\\frac  {\\partial ^{2}f}{\\partial x_{n}\\partial x_{1}}}&{\\frac  {\\partial ^{2}f}{\\partial x_{n}\\partial x_{2}}}&\\cdots &{\\frac  {\\partial ^{2}f}{\\partial x_{n}^{2}}}\\end{pmatrix}} = {\\begin{pmatrix}{\\nabla \\frac{\\partial f}{\\partial x_1}}\\\\{\\vdots}\\\\{{\\nabla \\frac{\\partial f}{\\partial x_n}}}\\end{pmatrix}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgqGb_FpYwN3"
      },
      "source": [
        "Algunos hints para implementar:\n",
        "* Ir definiendo al Hessiano por filas\n",
        "* Para cada $i$ utilizar `lambda` para definir la función $\\frac{\\partial f}{\\partial x_i}(x)$ (a partir de `derivada direccional`)\n",
        "* La fila $i$-ésima del Hessiano es aplicar `gradiente` a la función definida en el ítem anterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsZKA_S3YwN3"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "1. Implementar la función `hessiano` que, dados una función `f` y un punto `x`, aproxime $Hf(x)$.\n",
        "2. Implementar el Método de Newton con Modificación de Levenberg-Marquardt.\n",
        "3. Probar el método con la función de Rosenbrock con $x_0=(0,0)$ 😱\n",
        "4. Probar el método aplicándolo a la función de resta de exponenciales cuyo minimizador es $(1.1, 1.1)$. Comenzar en distintos puntos iniciales:\n",
        "* $x_0=(1,0)$\n",
        "* $x_0 =(2, 1.5)$\n",
        "* $x_0=(0.5, 0.5)$\n",
        "* $x_0=(0,0)$\n",
        "* $x_0=(-0.7, -0.2)$ <br>\n",
        "¿Qué sucede en el último caso? ¿Por qué? (Interpretar a partir del gráfico de la función)\n",
        "\n",
        "5. ¿Funciona el método si fijamos $t=1$?\n",
        "6. Comparar con Método del Gradiente y con Gradiente Conjugado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Ejercicio 1:\n",
        "#Ir definiendo al Hessiano por filas\n",
        "#Para cada i utilizar lambda para definir la función  ∂f∂xi(x)  (a partir de derivada direccional)\n",
        "#La fila i-ésima del Hessiano es aplicar gradiente a la función definida en el ítem anterior\n",
        "\n",
        "def derivada_direccional(f, x, d, h=1e-5):\n",
        "  return (f(x + h * d) - f(x - h * d)) / (2 * h)\n",
        "\n",
        "def gradiente(f, x, h=1e-5):\n",
        "  n = len(x)\n",
        "  res = np.zeros(n)\n",
        "  for i in range(n):\n",
        "      # Vector unitario en la dirección i\n",
        "      e_i = np.zeros(n)\n",
        "      e_i[i] = 1\n",
        "      # Derivada parcial de f respecto a la variable i\n",
        "      res[i] = derivada_direccional(f, x, e_i, h)\n",
        "  return res\n",
        "\n",
        "def hessiano(f, x, h=1e-8): #Hice modificaciones en H para que tome la fcion rosenbrock\n",
        "  n = len(x)\n",
        "  #H = np.array([])\n",
        "  H = np.zeros((n, n))  # Asegura una matriz 2D, para que no haya problemas al ejecutar rosenbrock\n",
        "  for i in range(n):\n",
        "      # Derivada parcial de f respecto a xi\n",
        "      parcial_f_xi = lambda x_val: derivada_direccional(f, x_val, np.eye(n)[i])\n",
        "      #H = np.append(H, gradiente(parcial_f_xi, x))\n",
        "      # Gradiente de la parcial_f_xi para obtener la fila i del Hessiano\n",
        "      H[i, :] = gradiente(parcial_f_xi, x)\n",
        "  return H\n",
        "\n",
        "\n",
        "\n",
        "#def fcion_prueba(x):\n",
        "#  x1, x2 = x\n",
        "#  return 2 * x1**2 + x1 * x2\n",
        "\n",
        "#x_0 = np.array([1, 1])\n",
        "#res = hessiano(fcion_prueba, x_0)\n",
        "#print(\"Hessiano de f en x0:\", res)"
      ],
      "metadata": {
        "id": "PcWghqn4dX72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Ejercicio 2:\n",
        "\n",
        "def busqueda_armijo(f, x, d, eta=0.2, betha=2, eps_parada=1e-4): #eta = η  En este ejercicio, eta es el alpha de Armijo de la teorica\n",
        "  t=1\n",
        "  gradiente_val = gradiente(f, x)\n",
        "  if f(x + t*d) <= f(x) + eta * t * np.dot(gradiente_val, d):\n",
        "    while f(x + t*d) <= f(x) + eta * t * np.dot(gradiente_val, d) and t>eps_parada: #agrego condicion para que t no sea demasiado pequeño\n",
        "      t = t * betha\n",
        "    return t / betha # Devuelvo el último paso válido\n",
        "  else:\n",
        "     while f(x + t*d) > f(x) + eta * t * np.dot(gradiente_val, d) and t>eps_parada: #agrego condicion para que t no sea demasiado pequeño\n",
        "      t = t / betha\n",
        "     return t\n",
        "\n",
        "\n",
        "def met_newton_modif_levenberg_marquardt(f, x0, eps=1e-8, k_max=1000, gamma=0.1):\n",
        "  k=0\n",
        "  x_k = np.array(x0)\n",
        "  while np.linalg.norm(gradiente(f, x_k)) > eps  and  k < k_max:\n",
        "    B = hessiano(f, x_k)\n",
        "    mu = min(np.linalg.eigvals(B))\n",
        "    if mu <= 0:\n",
        "      B = B + (-mu + gamma)\n",
        "    d_k = np.linalg.solve(B, -gradiente(f, x_k))\n",
        "    t_k = busqueda_armijo(f, x_k, d_k)\n",
        "    x_k = x_k + t_k * d_k\n",
        "    k = k + 1\n",
        "  return x_k, k\n"
      ],
      "metadata": {
        "id": "aWF31KOSnvfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA-vgrJAYwN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e8be23-2055-49ca-c8f9-e4befe07e6f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El método de Newton modificado da como minimo [0.02003667 0.00548376 0.02003667 0.00548376] y realiza 4 iteraciones\n"
          ]
        }
      ],
      "source": [
        "##Ejercicio 3: Aplicar el metodo a Rosenbrock en x0=[0,0]\n",
        "\n",
        "def rosenbrock(x):\n",
        "    \"\"\"\n",
        "    minimiser : x = (1,..., 1)\n",
        "    \"\"\"\n",
        "    x = x.flatten() # Asegura que esté en 1D para el cálculo\n",
        "    d = np.shape(x)[0]\n",
        "    return sum(100*(x[i+1]-x[i]**2)**2+(x[i]-1)**2 for i in range(d-1))\n",
        "\n",
        "\n",
        "x_0 = np.array([0, 0], dtype=float).reshape(-1, 1) # Punto inicial en formato bidimensional\n",
        "min_newton_modif, iter_newton_modif = met_newton_modif_levenberg_marquardt(rosenbrock, x_0)\n",
        "print(f\"El método de Newton modificado da como minimo {min_newton_modif.flatten()} y realiza {iter_newton_modif} iteraciones\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Ejercicio 4: Probar el método aplicándolo a la función de resta de exponenciales cuyo minimizador es (1.1,1.1)\n",
        "#Comenzar en distintos puntos iniciales:\n",
        "#x0=(1,0)\n",
        "#x0=(2,1.5)\n",
        "#x0=(0.5,0.5)\n",
        "#x0=(0,0)\n",
        "#x0=(−0.7,−0.2)\n",
        "#¿Qué sucede en el último caso? ¿Por qué? (Interpretar a partir del gráfico de la función)\n",
        "\n",
        "def resta_exponenciales(x):\n",
        "  x = x.flatten() # Asegura que esté en 1D para el cálculo\n",
        "  s1 = np.exp(-x[0] ** 2 - x[1] ** 2)\n",
        "  s2 = np.exp(-(x[0] - 1) ** 2 - (x[1] - 1) ** 2)\n",
        "  return (s1 - s2) * 2\n",
        "\n",
        "\n",
        "x_0_i = np.array([1, 0], dtype=float).reshape(-1, 1) # Punto inicial en formato bidimensional\n",
        "min_newton_modif_i, iter_newton_modif_i = met_newton_modif_levenberg_marquardt(resta_exponenciales, x_0_i)\n",
        "print(f\"El método de Newton modificado en [1,0] da como minimo {min_newton_modif_i.flatten()} y realiza {iter_newton_modif_i} iteraciones\")\n",
        "\n",
        "x_0_ii = np.array([2, 1.5], dtype=float).reshape(-1, 1) # Punto inicial en formato bidimensional\n",
        "min_newton_modif_ii, iter_newton_modif_ii = met_newton_modif_levenberg_marquardt(resta_exponenciales, x_0_ii)\n",
        "print(f\"El método de Newton modificado en [2, 1.5] da como minimo {min_newton_modif_ii.flatten()} y realiza {iter_newton_modif_ii} iteraciones\")\n",
        "\n",
        "#x_0_iii = np.array([0.5, 0.5], dtype=float).reshape(-1, 1) # Punto inicial en formato bidimensional\n",
        "#min_newton_modif_iii, iter_newton_modif_iii = met_newton_modif_levenberg_marquardt(resta_exponenciales, x_0_iii)\n",
        "#print(f\"El método de Newton modificado en [0.5, 0.5] da como minimo {min_newton_modif_iii.flatten()} y realiza {iter_newton_modif_iii} iteraciones\")\n",
        "#El error \"Singular matrix\" aparece cuando el método intenta calcular la inversa de una matriz que no es invertible (singular).\n",
        "#En el contexto del método de Newton modificado con el ajuste de Levenberg-Marquardt, este problema puede surgir cuando el hessiano en\n",
        "#algún punto es singular o está cerca de serlo, lo que impide la inversión necesaria para actualizar el punto.\n",
        "\n",
        "x_0_iv = np.array([0, 0], dtype=float).reshape(-1, 1) # Punto inicial en formato bidimensional\n",
        "min_newton_modif_iv, iter_newton_modif_iv = met_newton_modif_levenberg_marquardt(resta_exponenciales, x_0_iv)\n",
        "print(f\"El método de Newton modificado en [0, 0] da como minimo {min_newton_modif_iv.flatten()} y realiza {iter_newton_modif_iv} iteraciones\")\n",
        "\n",
        "#x_0_v = np.array([-0.7, -0.2], dtype=float).reshape(-1, 1) # Punto inicial en formato bidimensional\n",
        "#min_newton_modif_v, iter_newton_modif_v = met_newton_modif_levenberg_marquardt(resta_exponenciales, x_0_v)\n",
        "#print(f\"El método de Newton modificado en [-0.7, -0.2] da como minimo {min_newton_modif_v.flatten()} y realiza {iter_newton_modif_v} iteraciones\")\n",
        "\n",
        "\n",
        "def plot_fun(f, limites, points=None):\n",
        "    \"\"\"\n",
        "    f : función a graficar\n",
        "    limites : toma una tupla (x1,x2,y1,y2) de los límites del gráfico: grafica en el dominio [x1,x2] x [y1,y2]\n",
        "    points : lista de puntos a graficar sobre la superficie; se ingresa como una lista de tuplas (x,y,z)\n",
        "    \"\"\"\n",
        "    init_notebook_mode(connected=True)\n",
        "\n",
        "    x = np.linspace(limites[0], limites[1], 1000)\n",
        "    y = np.linspace(limites[2], limites[3], 1000)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = f((X, Y))\n",
        "    data = [go.Surface(x=x, y=y, z=Z)]\n",
        "    if points is not None:\n",
        "        for p in points:\n",
        "            data.append(go.Scatter3d(x=[p[0]], y=[p[1]], z=[p[2]], mode='markers'))\n",
        "    fig = go.Figure(data=data)\n",
        "    iplot(fig)\n",
        "\n",
        "%matplotlib inline\n",
        "def graficar_recorrido(f, limites, recorrido=None, levels=10):\n",
        "    \"\"\"\n",
        "    Función que grafica curvas de nivel y, opcionalmente, el recorrido de un método.\n",
        "    f : es la función a graficar (tiene que ir de R2 en R)\n",
        "    limites : es una lista o tupla de números: [a,b,c,d]. Va a graficar la función en el cuadrado [a,b] x [c,d]\n",
        "    recorrido : acepta una lista de arrays bidimensionales para graficar el recorrido de un método\n",
        "    levels : cantidad de curvas de nivel a graficar\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    x = np.linspace(limites[0], limites[1], 1000)\n",
        "    y = np.linspace(limites[2], limites[3], 1000)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = f((X, Y))\n",
        "    plt.contour(X,Y,Z, cmap='plasma', levels=levels)\n",
        "    if recorrido is not None:\n",
        "        x_coords = [x[0] for x in recorrido]\n",
        "        y_coords = [x[1] for x in recorrido]\n",
        "        plt.plot(x_coords, y_coords, marker='o', lw=2, ms=8)\n",
        "    plt.tight_layout()\n",
        "    plt.gca().set_aspect('equal', adjustable='box')\n",
        "    plt.show()\n",
        "\n",
        "graficar_recorrido(resta_exponenciales, [-1, 2, -1, 2], [min_newton_modif_i, min_newton_modif_ii, min_newton_modif_iv])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "8Qe5ZdgezyEu",
        "outputId": "6aa7b842-3514-4ed9-96d7-5f2aee02f2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El método de Newton modificado en [1,0] da como minimo [1.09983932 1.09983932 0.09983932 0.09983932] y realiza 7 iteraciones\n",
            "El método de Newton modificado en [2, 1.5] da como minimo [1.09983932 1.09983932 0.59983932 0.59983932] y realiza 5 iteraciones\n",
            "El método de Newton modificado en [0, 0] da como minimo [5.94877855 5.94877855 5.94877855 5.94877855] y realiza 1 iteraciones\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'flatten'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-b3d74da4908d>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mgraficar_recorrido\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresta_exponenciales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmin_newton_modif_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_newton_modif_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_newton_modif_iv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-97-b3d74da4908d>\u001b[0m in \u001b[0;36mgraficar_recorrido\u001b[0;34m(f, limites, recorrido, levels)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimites\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimites\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'plasma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecorrido\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-b3d74da4908d>\u001b[0m in \u001b[0;36mresta_exponenciales\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresta_exponenciales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Asegura que esté en 1D para el cálculo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}