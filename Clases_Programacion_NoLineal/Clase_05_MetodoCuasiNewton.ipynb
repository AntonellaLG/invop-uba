{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        },
        "id": "9OLP-MP_e2c_"
      },
      "source": [
        "### Introducción a la Investigación Operativa y la Optimización\n",
        "\n",
        "### • Clase 5  - Métodos Cuasi-Newton\n",
        "\n",
        "**Nazareno Faillace Mullen - Departamento de Matemática, FCEN, UBA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "4lVrDPUie2dB"
      },
      "source": [
        "La idea, como en el caso del Método de Newton, es aproximar $f$ mediante una expresión cuadrática. Sin embargo, en los métodos cuasi-Newton, se utiliza, en vez de $Hf(x)$, una matriz $B_k$ que sea simétrica definida positiva. La idea es que $B_k$ aproxime a $Hf(x_k)$.\n",
        "\n",
        "Como hemos visto, en el método de Newton la dirección de descenso (si $Hf(x_k)\\succ 0$) viene dada por:\n",
        "\n",
        "$$-Hf(x_k)^{-1}\\nabla f(x^{k})$$\n",
        "\n",
        "Dos enfoques: <br>\n",
        "• Aproximar $Hf(x_k)$ con matrices $B_k$ <br>\n",
        "• Aproximar $Hf(x_k)^{-1}$ con matrices $H_k$ [$\\leftarrow$ trabajamos con este]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "3gKHhvl2e2dC"
      },
      "source": [
        "### Algoritmo general de un método Cuasi-Newton\n",
        "\n",
        "Dados: $f,\\; x_0 \\in \\mathbb{R}^n, \\; H_0\\in \\mathbb{R}^{n\\times n}\\;\\;\\text{definida positiva},\\; \\varepsilon > 0, \\; k_{MAX} > 0$ <br>\n",
        "$k = 0$ <br>\n",
        "REPETIR  mientras $\\lVert \\nabla f(x_k) \\rVert > \\varepsilon$ y $k<k_{MAX}$:<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Definir $d_k = -H_k\\nabla f(x_k)$<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Obtener $t_k$ (sección áurea, Armijo o Wolfe)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Hacer $x_{k+1} = x_k + t_kd_k$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Determinar $H_{k+1}$ definida positiva<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $k=k+1$<br>\n",
        "DEVOLVER $x_k$\n",
        "\n",
        "__Obs:__ si $H_k = I \\rightarrow$ Método del Gradiente <br>\n",
        "si $H_k = Hf(x_k)^{-1} \\rightarrow$ Método de Newton\n",
        "\n",
        "__Obs:__ como $H_0$ podemos tomar la identidad, ya que es definida positiva. También podría tomarse $Hf(x_0)$ si es definida positiva."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradiente(f, x):\n",
        "    return np.array([f[i](x) for i in range(len(f))]).reshape(-1,1)\n",
        "\n",
        "def wolfe(A, x, d, c1 = 0.5, c2 = 0.75):\n",
        "  alfa = 0\n",
        "  t = 1\n",
        "  beta = np.inf\n",
        "  while True:\n",
        "    if f(x+t*d,A) > f(x,A) + c1*t*np.dot((A@x).T,d):\n",
        "      beta = t\n",
        "      t = 1/2 * (alfa + beta)\n",
        "    elif np.dot((A@(x+t*d)).T,d) < c2*np.dot((A@x).T,d):\n",
        "      alfa = t\n",
        "      if beta == np.inf:\n",
        "        t = 2*alfa\n",
        "      else:\n",
        "        t = 1/2 * (alfa + beta)\n",
        "    else:\n",
        "      break\n",
        "  return t\n",
        "\n",
        "\n",
        "def derivada_parcial(f,x,i):\n",
        "    h = 0.1\n",
        "    e_i = np.zeros(len(x))\n",
        "    e_i[i] = 1\n",
        "    z = (f(x + h*e_i) - f(x - h*e_i)) / (2*h)\n",
        "    h = h/2\n",
        "    y = (f(x + h*e_i) - f(x - h*e_i)) / (2*h)\n",
        "    error = np.linalg.norm(y-z)\n",
        "    eps = 1e-8\n",
        "    while error>eps and (y != np.nan) and (y != np.inf):\n",
        "        error = np.linalg.norm(y-z)\n",
        "        z = y\n",
        "        h = h/2\n",
        "        y = (f(x + h*e_i) - f(x - h*e_i)) / (2*h)\n",
        "    return z\n",
        "\n",
        "def gradiente(f, x):\n",
        "    return np.array([derivada_parcial(f, x, i) for i in range(len(x))])\n",
        "\n",
        "def broyden_mala(f, x0, H0, eps=1e-4, max_iter=1000):\n",
        "  k = 0\n",
        "  H_k = H0\n",
        "  d0 = -H0 @ gradiente(f(x0, A), x0)\n",
        "  t0 = wolfe(f, x0, d0)\n",
        "  x_k_prev = x0\n",
        "  x_k = x_k_prev - t_k * d_k\n",
        "  s_k = x_k - x_k_prev\n",
        "  gradiente_xk = gradiente(f(x_k, A), x_k)\n",
        "  gradiente_xk_prev = gradiente(f(x_k_prev, A), x_k_prev)\n",
        "  y_k = gradiente_xk - gradiente_xk_prev\n",
        "  while np.linalg.norm(gradiente_xk) > eps and k < max_iter:\n",
        "    d_k = -H_k @ gradiente_xk\n",
        "    s_k = x_k - x_k_prev\n",
        "    y_k = gradiente_xk - gradiente_xk_prev\n",
        "    t_k = wolfe(A, x_k, d_k)\n",
        "    x_k = x_k + t_k * d_k\n",
        "    H_k = H_k + (s_k - H_k * y_k)*(s_k - H_k * y_k).T/(y_k.T * (s_k - H_k*y_k))\n",
        "    k += 1\n",
        "  return x_k, k\n"
      ],
      "metadata": {
        "id": "m1v7uc3jneHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dfp(f, x0, H0, eps=1e-4, max_iter=1000):\n",
        "  k = 0\n",
        "  H_k = H0\n",
        "  d0 = -H0 @ gradiente(f(x0, A), x0)\n",
        "  t0 = wolfe(f, x0, d0)\n",
        "  x_k_prev = x0\n",
        "  x_k = x_k_prev - t_k * d_k\n",
        "  s_k = x_k - x_k_prev\n",
        "  gradiente_xk = gradiente(f(x_k, A), x_k)\n",
        "  gradiente_xk_prev = gradiente(f(x_k_prev, A), x_k_prev)\n",
        "  y_k = gradiente_xk - gradiente_xk_prev\n",
        "  while np.linalg.norm(gradiente_xk) > eps and k < max_iter:\n",
        "    d_k = -H_k @ gradiente_xk\n",
        "    s_k = x_k - x_k_prev\n",
        "    y_k = gradiente_xk - gradiente_xk_prev\n",
        "    t_k = wolfe(A, x_k, d_k)\n",
        "    x_k = x_k + t_k * d_k\n",
        "    H_k = H_k + (s_k * s_k.T)/(y_k.T * s_k) - (H_k * y_k * y_k.T * H_k)/(y_k.T * H_k * y_k)\n",
        "    k += 1\n",
        "  return x_k, k"
      ],
      "metadata": {
        "id": "rfHaZSKUy8c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bfgs(f, x0, H0, eps=1e-4, max_iter=1000):\n",
        "  k = 0\n",
        "  H_k = H0\n",
        "  d0 = -H0 @ gradiente(f(x0, A), x0)\n",
        "  t0 = wolfe(f, x0, d0)\n",
        "  x_k_prev = x0\n",
        "  x_k = x_k_prev - t_k * d_k\n",
        "  s_k = x_k - x_k_prev\n",
        "  gradiente_xk = gradiente(f(x_k, A), x_k)\n",
        "  gradiente_xk_prev = gradiente(f(x_k_prev, A), x_k_prev)\n",
        "  y_k = gradiente_xk - gradiente\n",
        "  while np.linalg.norm(gradiente_xk) > eps and k < max_iter:\n",
        "    d_k = -H_k @ gradiente_xk\n",
        "    s_k = x_k - x_k_prev\n",
        "    y_k = gradiente_xk - gradiente_xk_prev\n",
        "    t_k = wolfe(A, x_k, d_k)\n",
        "    x_k = x_k + t_k * d_k\n",
        "    H_k = H_k + (1 + (y_k.T * H_k * y_k)/(s_k.T * y_k)) * (s_k * s_k.T)/(s_k.T * y_k) - (s_k * y_k.T * H_k + H_k * y_k * s_k.T)/(s_k.T * y_k)\n",
        "    k += 1\n",
        "  return x_k, k"
      ],
      "metadata": {
        "id": "MCOQ7-D7zz_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "XE93picDe2dC"
      },
      "source": [
        "Sean $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ y $s_k = x_{k+1} - x_k$, una propiedad que debe satisfacer $H_{k+1}$ definida por el algoritmo es que:\n",
        "$$H_{k+1}y_j = s_j \\quad \\forall j=0,1,\\dots,k$$\n",
        "\n",
        "### Broyden (Mala)\n",
        "\n",
        "$$H_{k+1} = H_k + \\dfrac{(s_k-H_ky_k)(s_k-H_ky_k)^T}{y_k^T(s_k-H_ky_k)}$$\n",
        "\n",
        "### Método DFP (Davindon, Fletcher y Powell)\n",
        "\n",
        "$$H_{k+1} = H_k + \\dfrac{s_k(s_k)^T}{(y_k)^Ts_k} - \\dfrac{H_ky_k(y_k)^TH_k}{(y_k)^TH_ky_k}$$\n",
        "\n",
        "### Método BFGS (Broyden, Fletcher, Goldfarb y Shanno)\n",
        "\n",
        "$$H_{k+1} = H_k + \\left(1 + \\dfrac{(y_k)^TH_ky_k}{(s_k)^Ty_k}\\right)\\dfrac{s_k(s_k)^T}{(s_k)^Ty_k} - \\dfrac{s_k(y_k)^TH_k + H_ky_k(s_k)^T}{(s_k)^Ty_k} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQUsWIEEe2dD"
      },
      "source": [
        "### Importante\n",
        "\n",
        "Como en general se trabaja con vectores columna:<br>\n",
        "• $\\mathbf{u^T}\\mathbf{v} = <\\mathbf{u}, \\mathbf{v}>\\rightarrow$ `u @ v` <br>\n",
        "\n",
        "• $ {\\displaystyle \\mathbf{u} \\mathbf{v^T} = \\mathbf {u} \\otimes \\mathbf {v} ={\\begin{bmatrix}u_{1}v_{1}&u_{1}v_{2}&\\dots &u_{1}v_{n}\\\\u_{2}v_{1}&u_{2}v_{2}&\\dots &u_{2}v_{n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\u_{m}v_{1}&u_{m}v_{2}&\\dots &u_{m}v_{n}\\end{bmatrix}}}\\rightarrow$ `np.outer(u, v)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7iUrTRae2dD"
      },
      "source": [
        "### Método de Barzilai-Borwein-Raydan (BBR)\n",
        "\n",
        "Sean $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ y $s_k = x_{k+1} - x_k$.\n",
        "\n",
        "Dados: $f,\\; x^0 \\in \\mathbb{R}^n, \\; \\varepsilon > 0, \\; k_{MAX} > 0$ <br>\n",
        "Definir $d_0 = -\\nabla f(x_k)$ <br>\n",
        "Obtener $t_0$ (sección áurea, Armijo o Wolfe) <br>\n",
        "$x_1 = x_0 + t_0* d_0$ <br>\n",
        "$k = 1$<br>\n",
        "REPETIR  mientras $\\lVert \\nabla f(x_k) \\rVert > \\varepsilon$ y $k<k_{MAX}$:<br>\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Definir $d_k = -\\nabla f(x_k)$<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Definir $t_k = \\dfrac{s_{k-1}^Ts_{k-1}}{s_{k-1}^Ty_{k-1}}$ ( si $f$ es cuadrática, $t_k = \\dfrac{s_{k-1}^T s_{k-1}}{s_{k-1} ^T A s_{k-1}}$) <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Hacer $x_{k+1} = x_k + t_kd_k$ <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $k=k+1$<br>\n",
        "DEVOLVER $x_k$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY_WCerGe2dD"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "1. Implementar los tres métodos de Cuasi-Newton para el caso de **funciones cuadráticas** $f(x)=\\frac{1}{2}x^T A x + bx + c$ con $A\\succ 0$. Debe tomar como input la matriz $A$, el vector $b$, el vector inicial $x_0$ y la cantidad máxima de iteraciones $k_{MAX}$. Utilizar que para este tipo de funciones sabemos que: <br>\n",
        "• $\\nabla f(x_k) = Ax_k +b$ <br>\n",
        "• $t_k = -\\dfrac{(Ax_k +b)^T d_k}{(d_k)^TAd_k}$ <br>\n",
        "• $y_k=\\nabla f(x_{k+1}) - \\nabla f(x_k)=(Ax_{k+1} + b) - (Ax_k+b) = A(x_{k+1} - x_k)= As_k$\n",
        "2. Testear los cuatro métodos con las funciones cuadráticas dadas por $f(x)=\\frac{1}{2}x^T A_i x$ para cada una de las $A_i$ que figuran debajo. Comparar el número de iteraciones de cada uno con el de Gradiente Conjugado.\n",
        "3. Para $A_4$ graficar el recorrido que DFP y el recorrido de Gradiente Conjugado.\n",
        "4. Para $A_4$, comparar el recorrido realizado por el Método del Gradiente y el recorrido de BBR. **Utilizar $x_0 = (-0.15, 1)$** como punto inicial.\n",
        "5. Implementar los cuatro métodos para funciones en general y aplicarlos para hallar el minimizador de la función de resta de exponenciales. Comparar con Gradiente Conjugado. Se pueden elegir, por ejemplo, estos puntos iniciales: <br>\n",
        "• $x_0=(1,0)$ <br>\n",
        "• $x_0 =(2, 1.5)$ <br>\n",
        "• $x_0=(0.5, 0.5)$ <br>\n",
        "• $x_0=(0,0)$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi1ZliKSe2dD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm, eigvals, solve\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "\n",
        "A1 = np.array([[8, 3, 3, 6, 5, 4, 4, 3, 6, 3],\n",
        "             [3, 4, 2, 2, 2, 1, 3, 3, 3, 2],\n",
        "             [3, 2, 5, 2, 1, 2, 4, 2, 4, 1],\n",
        "             [6, 2, 2, 6, 3, 2, 4, 2, 4, 2],\n",
        "             [5, 2, 1, 3, 5, 4, 1, 2, 4, 3],\n",
        "             [4, 1, 2, 2, 4, 5, 1, 2, 5, 2],\n",
        "             [4, 3, 4, 4, 1, 1, 6, 2, 4, 2],\n",
        "             [3, 3, 2, 2, 2, 2, 2, 4, 4, 2],\n",
        "             [6, 3, 4, 4, 4, 5, 4, 4, 8, 3],\n",
        "             [3, 2, 1, 2, 3, 2, 2, 2, 3, 4]])\n",
        "\n",
        "A2 = np.array([[2, 0, 1, 0, 1],\n",
        "               [0, 2, 1, 1, 1],\n",
        "               [1, 1, 3, 1, 1],\n",
        "               [0, 1, 1, 1, 0],\n",
        "               [1, 1, 1, 0, 2]])\n",
        "\n",
        "A3 = np.diag(np.random.randint(1, 5, 100))\n",
        "\n",
        "A4 = np.array([[10, 0], [0, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK1etn9be2dE"
      },
      "outputs": [],
      "source": [
        "def resta_exponenciales(x):\n",
        "    s1 = np.exp(-x[0] ** 2 - x[1] ** 2)\n",
        "    s2 = np.exp(-(x[0] - 1) ** 2 - (x[1] - 1) ** 2)\n",
        "    return (s1 - s2) * 2\n",
        "\n",
        "def a_forma_cuadratica(A):\n",
        "    \"\"\"\n",
        "    Transforma la función dada por (1/2)(x^T A x) a una función dada en términos de x1 y x2 para que sea posible\n",
        "    graficar sus curvas de nivel en R2.\n",
        "    A tiene que ser una matriz de 2x2\n",
        "    \"\"\"\n",
        "    def forma_cuadratica(x):\n",
        "        return 0.5*(A[0,0]*(x[0]**2) + (A[0,1]+A[1,0])*x[0]*x[1] + A[1,1]*(x[1]**2))\n",
        "    return forma_cuadratica\n",
        "\n",
        "def plot_fun(f, limites, points=None):\n",
        "    \"\"\"\n",
        "    f : función a graficar\n",
        "    limites : toma una tupla (x1,x2,y1,y2) de los límites del gráfico: grafica en el dominio [x1,x2] x [y1,y2]\n",
        "    points : lista de puntos a graficar sobre la superficie; se ingresa como una lista de tuplas (x,y,z)\n",
        "    \"\"\"\n",
        "    init_notebook_mode(connected=True)\n",
        "\n",
        "    x = np.linspace(limites[0], limites[1], 1000)\n",
        "    y = np.linspace(limites[2], limites[3], 1000)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = f((X, Y))\n",
        "    data = [go.Surface(x=x, y=y, z=Z)]\n",
        "    if points is not None:\n",
        "        for p in points:\n",
        "            data.append(go.Scatter3d(x=[p[0]], y=[p[1]], z=[p[2]], mode='markers'))\n",
        "    fig = go.Figure(data=data)\n",
        "    iplot(fig)\n",
        "\n",
        "%matplotlib notebook\n",
        "def graficar_recorrido(f, limites, recorrido=None, levels=10):\n",
        "    \"\"\"\n",
        "    Función que grafica curvas de nivel y, opcionalmente, el recorrido de un método.\n",
        "    f : es la función a graficar (tiene que ir de R2 en R)\n",
        "    limites : es una lista o tupla de números: [a,b,c,d]. Va a graficar la función en el cuadrado [a,b] x [c,d]\n",
        "    recorrido : acepta una lista de arrays bidimensionales para graficar el recorrido de un método\n",
        "    levels : cantidad de curvas de nivel a graficar\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    x = np.linspace(limites[0], limites[1], 1000)\n",
        "    y = np.linspace(limites[2], limites[3], 1000)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = f((X, Y))\n",
        "    plt.contour(X,Y,Z, cmap='plasma', levels=levels)\n",
        "    if recorrido is not None:\n",
        "        x_coords = [x[0] for x in recorrido]\n",
        "        y_coords = [x[1] for x in recorrido]\n",
        "        plt.plot(x_coords, y_coords, marker='o', lw=2, ms=8)\n",
        "    plt.tight_layout()\n",
        "    plt.gca().set_aspect('equal', adjustable='box')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syuClFWQe2dE"
      },
      "outputs": [],
      "source": [
        "# EJEMPLO PARA GRAFICAR EL RECORRIDO EN EL EJERCICIO 3 y 4\n",
        "x_opt, iteraciones, recorrido = metodo_gradiente(A4, np.zeros(2), np.ones(2), 100)\n",
        "f = a_forma_cuadratica(A4)\n",
        "graficar_recorrido(f, [-1, 1, -1, 1], recorrido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXgkuTWbe2dF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}